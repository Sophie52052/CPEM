{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "#from skimage.measure import structural_similarity as ssim\n",
    "#from sporco import util\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "import multiprocessing\n",
    "import datetime\n",
    "import hdf5storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnn(x, input_size, output_size, keep_prob, stddev=0.01, constant=0.0001, dropout=True, end=False):\n",
    "    fc_w = tf.Variable(tf.truncated_normal([input_size,output_size], stddev=stddev,seed=np.random.seed(2018)))\n",
    "    fc_b = tf.Variable(tf.constant(constant,shape=[output_size]), dtype=tf.float32)\n",
    "    fc_h = tf.nn.relu(tf.matmul(x,fc_w)+fc_b) if not end else tf.matmul(x,fc_w)+fc_b\n",
    "    return tf.nn.dropout(fc_h, keep_prob,seed=np.random.seed(2018)) if dropout else fc_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn(x, input_size, output_size, nlayers, nparameters, keep_prob):\n",
    "    if nlayers == 1:\n",
    "        h1 = fnn(x, input_size, output_size, keep_prob, end=True)\n",
    "    elif nlayers == 2:\n",
    "        h1 = fnn(fnn(x, input_size, nparameters, keep_prob, end=False), nparameters, output_size, keep_prob, end=True)\n",
    "    elif nlayers >= 3:\n",
    "        h0 = fnn(x, input_size, nparameters, keep_prob, end=False)\n",
    "        for j in range(0,nlayers-2):\n",
    "            if j == 0:\n",
    "                h1 = fnn(h0, nparameters, nparameters, keep_prob, end=False)\n",
    "            else:\n",
    "                h1 = fnn(h1, nparameters, nparameters, keep_prob, end=False)\n",
    "        h1 = fnn(h1, nparameters, output_size, keep_prob, end=True)\n",
    "    else:\n",
    "        print(\"# of layers can't be smaller than 0\")\n",
    "    return h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc(train_data, train_label, test_data, test_label):\n",
    "    rf = RandomForestClassifier(n_estimators=150,\n",
    "                                    criterion='gini',\n",
    "                                    max_depth=None,\n",
    "                                    min_samples_split=2,\n",
    "                                    min_samples_leaf=1,\n",
    "                                    min_weight_fraction_leaf=0.0,\n",
    "                                    max_features=None,\n",
    "                                    max_leaf_nodes=None,\n",
    "                                    bootstrap=True,\n",
    "                                    oob_score=False,\n",
    "                                    n_jobs=10,\n",
    "                                    random_state=123,\n",
    "                                    verbose=0,\n",
    "                                    warm_start=False,\n",
    "                                    class_weight=None)\n",
    "    rf.fit(train_data, train_label.ravel())\n",
    "    result = rf.predict_proba(test_data)\n",
    "    acc = 0.0\n",
    "    for i in range(np.shape(test_data)[0]):\n",
    "        r = np.argmax(result[i])\n",
    "        if r == test_label[i]:\n",
    "            acc += 1\n",
    "    acc /= np.shape(test_data)[0]\n",
    "    acc *= 100\n",
    "    return acc, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn(train_data, train_label, test_data, test_label):\n",
    "    g = tf.Graph()\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    batch_size = 10\n",
    "    input_size = np.shape(train_data)[1]\n",
    "    output_size = 31\n",
    "\n",
    "    with g.as_default():\n",
    "        p_x = tf.placeholder(tf.float32, [batch_size, 1, input_size, 1])\n",
    "        p_y = tf.placeholder(tf.float32, [batch_size, output_size])\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        h10_flat = tf.reshape(p_x, [batch_size,-1])\n",
    "        h1 = fnn(h10_flat, input_size, 2048, keep_prob, end=False)\n",
    "        h2 = fnn(h1, 2048, 2048, keep_prob, end=False)\n",
    "        h3 = fnn(h2, 2048, 31, keep_prob, end=True)\n",
    "        h4 = tf.reshape(h3, [batch_size, 31])\n",
    "        h_c = tf.nn.softmax(h4)\n",
    "        loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels=p_y, logits=h4))\n",
    "        optim = tf.train.AdamOptimizer(1e-5)\n",
    "        trainer = optim.minimize(loss)\n",
    "    \n",
    "    accuracy = 0.0\n",
    "    result = np.zeros([np.shape(test_data)[0], 31])\n",
    "    with tf.Session(graph=g, config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for e in range(0,120):\n",
    "            loss_tot = 0.0\n",
    "            for i in range(0,int(np.ceil(np.shape(train_data)[0]/batch_size))):\n",
    "                a = np.random.randint(0,np.shape(train_data)[0],size=batch_size)\n",
    "                x = train_data[a].reshape([batch_size, 1, input_size, 1])#[4,1,18181,1]\n",
    "                y = np.zeros([batch_size, output_size])\n",
    "                index = train_label[a]\n",
    "                for u in range(0,batch_size):\n",
    "                    y[u,index[u]] = 1\n",
    "                _ , loss_val = sess.run([trainer, loss], feed_dict={p_x:x, p_y:y, keep_prob:0.6})\n",
    "                loss_tot += loss_val\n",
    "            print(\"%d epoch Loss: %f\" % (e,(loss_tot)/np.shape(train_data)[0]))\n",
    "        temp = 0\n",
    "        for i in range(0,int(np.floor(np.shape(test_data)[0]/batch_size))):\n",
    "            x = test_data[i*batch_size:(i+1)*batch_size].reshape([batch_size, 1, input_size, 1])\n",
    "            out = sess.run(h_c, feed_dict={p_x:x, keep_prob:1})\n",
    "            for j in range(0, batch_size):\n",
    "                t = np.squeeze(out[j])\n",
    "                result[temp] = t\n",
    "                temp+=1\n",
    "        remain = int(np.shape(test_data)[0]-np.floor(np.shape(test_data)[0]/batch_size)*batch_size)\n",
    "        if remain > 0:\n",
    "            x = test_data[-batch_size-1:-1].reshape([batch_size, 1, input_size, 1])\n",
    "            out = sess.run(h_c, feed_dict={p_x:x, keep_prob:1})\n",
    "            for j in range(0,int(remain)):\n",
    "                t = np.squeeze(out[j+(batch_size-remain)])\n",
    "                result[temp] = t\n",
    "                temp+=1\n",
    "        for i in range(0,np.shape(test_data)[0]):\n",
    "            ind = np.argmax(np.squeeze(result[i]))\n",
    "            if ind == test_label[i]:\n",
    "                accuracy += 1\n",
    "        accuracy /= np.shape(test_data)[0]*0.01\n",
    "        sess.close()\n",
    "    return accuracy, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataID = hdf5storage.loadmat('data.mat')\n",
    "data = np.array(dataID['data'], dtype=np.float32)\n",
    "gt1 = scipy.io.loadmat('label.mat')\n",
    "label = np.array(gt1['label'], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Outer_loop = 10\n",
    "Inner_loop = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1, penalty=\"l1\", dual=False).fit(data, label)\n",
    "coef = np.squeeze(np.sum(np.square(np.array(lsvc.coef_)), axis=0))\n",
    "print(lsvc.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelectFromModel(lsvc, prefit=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LinearSVC(C=1, dual=False, penalty='l1'), prefit=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False  True False]\n"
     ]
    }
   ],
   "source": [
    "X_new = model.transform(data) \n",
    "print(model.get_support()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: -0.00000\n",
      "Feature: 1, Score: 12.44483\n",
      "Feature: 2, Score: -0.00000\n",
      "Feature: 3, Score: -0.00000\n",
      "Feature: 4, Score: 93.32225\n",
      "Feature: 5, Score: 86.50811\n",
      "Feature: 6, Score: 26.74607\n",
      "Feature: 7, Score: 3.28535\n",
      "Feature: 8, Score: -0.00000\n",
      "Feature: 9, Score: 0.00000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# linear\n",
    "# linear regression feature importance\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "# define the model\n",
    "model = LinearRegression()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# get importance\n",
    "importance = model.coef_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.02220122,  0.31563495,  0.82797464, ..., -0.50446586,\n",
       "         0.23009474,  0.76201118],\n",
       "       [ 0.71256194,  1.74103872, -1.21466535, ...,  1.04131149,\n",
       "        -0.75850596,  0.74791592],\n",
       "       [ 0.08338884,  0.92829021,  1.45167891, ...,  1.22393601,\n",
       "         0.3416886 , -0.12517266],\n",
       "       ...,\n",
       "       [ 0.12182436,  0.74220833, -0.64488697, ..., -2.37934499,\n",
       "         1.82039313, -1.55531804],\n",
       "       [ 0.00820639, -0.89191578,  0.14747174, ..., -1.78611048,\n",
       "         0.71238157, -1.07498942],\n",
       "       [-0.43805451,  0.29078795,  0.17794556, ..., -0.18581086,\n",
       "        -0.26120192,  0.8632634 ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.01639344,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.01204819],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.0041841 , 0.0125523 ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.09090909, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.00714286]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.78228246e-14,  1.24448279e+01, -2.30926389e-14, -2.33146835e-14,\n",
       "        9.33222545e+01,  8.65081100e+01,  2.67460667e+01,  3.28534640e+00,\n",
       "       -2.48689958e-14,  3.10862447e-14])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-07e97ad5028d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# summarize feature importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Feature: %0d, Score: %.5f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "# get importance\n",
    "importance0 = lsvc.coef_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance0):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r 31 c 35565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lsvc.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefidx = np.argsort(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefidx1 = np.sort(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , ..., 0.        , 0.07610835,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103.13176260155834"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefidx1[35564]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0, 22105, 22104, 22103, 22102, 22101, 22100, 22098, 22097,\n",
       "       22096])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefidx[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[    0, 22107, 22106, 22105, 22104, 22103, 22101, 22098, 22097,\n",
    "       22096]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0, 22105, 22104, 22103, 22102, 22101, 22100, 22098, 22097,\n",
    "       22096]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Accuracy':MD_acc,'Feature Number':MD_num, 'Model':MD_md}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\",rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.boxplot(x = \"Feature Number\", y = \"Accuracy\", hue=\"Model\", data = df, palette = \"Set3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-944e9c53391f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtot_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInner_loop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#lasso = Lasso()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mlsvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"l1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mcoef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             self.loss, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"crammer_singer\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    970\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#Load data\n",
    "\n",
    "    \n",
    "    #Initialize\n",
    "    label -= 1\n",
    "    np.random.seed(2018)\n",
    "\n",
    "\n",
    "    \n",
    "    t_index = np.random.permutation(int(np.shape(data)[0]/Outer_loop)*Outer_loop)\n",
    "    t_index = np.reshape(t_index, [Outer_loop, -1])\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    \n",
    "    box = np.array([4000], dtype=np.int32)\n",
    "    flag = 0\n",
    "    for test_index in t_index:\n",
    "        if flag == Outer_loop-1:\n",
    "            test_index = np.array(np.concatenate((test_index, np.array(range(int(np.shape(data)[0]/Outer_loop)*Outer_loop,np.shape(data)[0]))), axis=0), dtype=np.int32)\n",
    "        train_index = np.setdiff1d(np.array(range(0,np.shape(data)[0])), test_index)\n",
    "        train_data = data[train_index]\n",
    "        train_label = label[train_index]\n",
    "        test_data = data[test_index]\n",
    "        test_label = label[test_index]\n",
    "        \n",
    "        kf = np.random.permutation(int(np.shape(train_data)[0]/Inner_loop)*Inner_loop)\n",
    "        kf = kf.reshape([Inner_loop]+[-1])\n",
    "        val_result = np.zeros([np.shape(train_data)[0],48], dtype=np.float32)\n",
    "        \n",
    "        tot_acc = np.zeros([Inner_loop,5], dtype=np.float32)\n",
    "        #lasso = Lasso()\n",
    "        lsvc = LinearSVC(C=1, penalty=\"l1\", dual=False).fit(data, label)\n",
    "        coef = np.squeeze(np.sum(np.square(np.array(lsvc.coef_)), axis=0))\n",
    "        print(lsvc.coef_)\n",
    "        #coef = np.squeeze(np.sum(np.square(np.array(lasso.coef_)), axis=0))\n",
    "        coefidx = np.argsort(coef)\n",
    "#         for inner_fold in range(0,Inner_loop):\n",
    "#             val_test_ind = kf[inner_fold]\n",
    "#             if inner_fold == Inner_loop-1:\n",
    "#                 val_test_ind = np.array(np.concatenate((val_test_ind,np.array(range(int(np.shape(train_data)[0]/Outer_loop)*Outer_loop,np.shape(train_data)[0]),dtype=np.int32)), axis=0),dtype=np.int32)\n",
    "            \n",
    "#             val_train_ind = np.setdiff1d(np.array(range(0,np.shape(train_data)[0]),dtype=np.int32), val_test_ind)\n",
    "#             val_train = train_data[val_train_ind]\n",
    "#             val_test = train_data[val_test_ind]\n",
    "#             val_train_label = train_label[val_train_ind]\n",
    "#             val_test_label = train_label[val_test_ind]\n",
    "#             temp = 0\n",
    "#             for item in box:\n",
    "#                 idx = coefidx[-item:]\n",
    "#                 vtrain = val_train[:,idx]\n",
    "#                 vtest = val_test[:,idx]\n",
    "#                 nn_acc, result_nn = dnn(vtrain, val_train_label, vtest, val_test_label)\n",
    "#                 rf_acc, result_rf = rfc(vtrain, val_train_label, vtest, val_test_label)\n",
    "#                 en_acc = 0.0\n",
    "#                 for i in range(0,np.shape(vtest)[0]):\n",
    "#                     r = np.argmax(result_nn[i]+result_rf[i])\n",
    "#                     if r == val_test_label[i]:\n",
    "#                         en_acc += 1\n",
    "#                 en_acc /= np.shape(vtest)[0]*0.01\n",
    "#                 tot_acc[inner_fold,temp] = en_acc\n",
    "#                 print(\"Inner_fold # of features: %d, Neural network accuracy: %f, Random forests accuracy: %f, Ensemble accuracy: %f\" % (item, nn_acc, rf_acc, en_acc))\n",
    "#                 temp += 1\n",
    "        \n",
    "#         u = np.sum(tot_acc,0)\n",
    "       \n",
    "#         best_n = box[np.argmax(u)]\n",
    "#         idx = coefidx[-best_n:]\n",
    "        \n",
    "#         tr_data = train_data[:,idx]\n",
    "#         te_data = test_data[:,idx]\n",
    "#         nn_acc, result_nn = dnn(tr_data, train_label, te_data, test_label)\n",
    "#         rf_acc, result_rf = rfc(tr_data, train_label, te_data, test_label)\n",
    "#         en_acc = 0.0\n",
    "#         for i in range(0,np.shape(te_data)[0]):\n",
    "#             r = np.argmax(result_nn[i]+result_rf[i])\n",
    "#             if r == test_label[i]:\n",
    "#                 en_acc += 1\n",
    "#         en_acc /= np.shape(te_data)[0]*0.01\n",
    "#         print(\"Outer_fold # of features:  %d, Neural network accuracy: %f, Random forests accuracy: %f, Ensemble accuracy: %f\" % (best_n, nn_acc, rf_acc, en_acc))\n",
    "        flag += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
