{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "import multiprocessing\n",
    "import datetime\n",
    "import hdf5storage\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnn(x, input_size, output_size, keep_prob, stddev=0.01, constant=0.0001, dropout=True, end=False):\n",
    "    fc_w = tf.Variable(tf.truncated_normal([input_size,output_size], stddev=stddev,seed=np.random.seed(2018)))\n",
    "    fc_b = tf.Variable(tf.constant(constant,shape=[output_size]), dtype=tf.float32)\n",
    "    fc_h = tf.nn.relu(tf.matmul(x,fc_w)+fc_b) if not end else tf.matmul(x,fc_w)+fc_b\n",
    "    return tf.nn.dropout(fc_h, keep_prob,seed=np.random.seed(2018)) if dropout else fc_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn(x, input_size, output_size, nlayers, nparameters, keep_prob):\n",
    "    if nlayers == 1:\n",
    "        h1 = fnn(x, input_size, output_size, keep_prob, end=True)\n",
    "    elif nlayers == 2:\n",
    "        h1 = fnn(fnn(x, input_size, nparameters, keep_prob, end=False), nparameters, output_size, keep_prob, end=True)\n",
    "    elif nlayers >= 3:\n",
    "        h0 = fnn(x, input_size, nparameters, keep_prob, end=False)\n",
    "        for j in range(0,nlayers-2):\n",
    "            if j == 0:\n",
    "                h1 = fnn(h0, nparameters, nparameters, keep_prob, end=False)\n",
    "            else:\n",
    "                h1 = fnn(h1, nparameters, nparameters, keep_prob, end=False)\n",
    "        h1 = fnn(h1, nparameters, output_size, keep_prob, end=True)\n",
    "    else:\n",
    "        print(\"# of layers can't be smaller than 0\")\n",
    "    return h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc(train_data, train_label, test_data, test_label):\n",
    "    rf = RandomForestClassifier(n_estimators=150,\n",
    "                                    criterion='gini',\n",
    "                                    max_depth=None,\n",
    "                                    min_samples_split=2,\n",
    "                                    min_samples_leaf=1,\n",
    "                                    min_weight_fraction_leaf=0.0,\n",
    "                                    max_features=None,\n",
    "                                    max_leaf_nodes=None,\n",
    "                                    bootstrap=True,\n",
    "                                    oob_score=False,\n",
    "                                    n_jobs=-1,\n",
    "                                    random_state=123,\n",
    "                                    verbose=0,\n",
    "                                    warm_start=False,\n",
    "                                    class_weight=None)\n",
    "    rf.fit(train_data, train_label.ravel())\n",
    "    result = rf.predict_proba(test_data)\n",
    "    acc = 0.0\n",
    "    for i in range(np.shape(test_data)[0]):\n",
    "        r = np.argmax(result[i])\n",
    "        if r == test_label[i]:\n",
    "            acc += 1\n",
    "    acc /= np.shape(test_data)[0]\n",
    "    acc *= 100\n",
    "    return acc, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(train_data, train_label, test_data, test_label):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "    neigh.fit(train_data, train_label.ravel())\n",
    "    result = neigh.predict_proba(test_data)\n",
    "    acc = 0.0\n",
    "    for i in range(np.shape(test_data)[0]):\n",
    "        r = np.argmax(result[i])\n",
    "        if r == test_label[i]:\n",
    "            acc += 1\n",
    "    acc /= np.shape(test_data)[0]\n",
    "    acc *= 100\n",
    "    return acc, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ovr(train_data, train_label, test_data, test_label):\n",
    "    clf = OneVsRestClassifier(SVC(probability=True))\n",
    "    clf.fit(train_data, train_label.ravel())\n",
    "    result = clf.predict_proba(test_data)\n",
    "    \n",
    "    acc = 0.0\n",
    "    for i in range(np.shape(test_data)[0]):\n",
    "        r = np.argmax(result[i])\n",
    "        if r == test_label[i]:\n",
    "            acc += 1\n",
    "    acc /= np.shape(test_data)[0]\n",
    "    acc *= 100\n",
    "    return acc, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn(train_data, train_label, test_data, test_label):\n",
    "    g = tf.Graph()\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    batch_size = 10\n",
    "    input_size = np.shape(train_data)[1]\n",
    "    output_size = 31\n",
    "\n",
    "    with g.as_default():\n",
    "        p_x = tf.placeholder(tf.float32, [batch_size, 1, input_size, 1])\n",
    "        p_y = tf.placeholder(tf.float32, [batch_size, output_size])\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        h10_flat = tf.reshape(p_x, [batch_size,-1])\n",
    "        h1 = fnn(h10_flat, input_size, 2048, keep_prob, end=False)\n",
    "        h2 = fnn(h1, 2048, 2048, keep_prob, end=False)\n",
    "        h3 = fnn(h2, 2048, 31, keep_prob, end=True)\n",
    "        h4 = tf.reshape(h3, [batch_size, 31])\n",
    "        h_c = tf.nn.softmax(h4)\n",
    "        loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels=p_y, logits=h4))\n",
    "        optim = tf.train.AdamOptimizer(1e-5)\n",
    "        trainer = optim.minimize(loss)\n",
    "    \n",
    "    accuracy = 0.0\n",
    "    result = np.zeros([np.shape(test_data)[0], 31])\n",
    "    with tf.Session(graph=g, config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for e in range(0,120):\n",
    "            loss_tot = 0.0\n",
    "            for i in range(0,int(np.ceil(np.shape(train_data)[0]/batch_size))):\n",
    "                a = np.random.randint(0,np.shape(train_data)[0],size=batch_size)\n",
    "                x = train_data[a].reshape([batch_size, 1, input_size, 1])#[4,1,18181,1]\n",
    "                y = np.zeros([batch_size, output_size])\n",
    "                index = train_label[a]\n",
    "                for u in range(0,batch_size):\n",
    "                    y[u,index[u]] = 1\n",
    "                _ , loss_val = sess.run([trainer, loss], feed_dict={p_x:x, p_y:y, keep_prob:0.6})\n",
    "                loss_tot += loss_val\n",
    "            print(\"%d epoch Loss: %f\" % (e,(loss_tot)/np.shape(train_data)[0]))\n",
    "        temp = 0\n",
    "        for i in range(0,int(np.floor(np.shape(test_data)[0]/batch_size))):\n",
    "            x = test_data[i*batch_size:(i+1)*batch_size].reshape([batch_size, 1, input_size, 1])\n",
    "            out = sess.run(h_c, feed_dict={p_x:x, keep_prob:1})\n",
    "            for j in range(0, batch_size):\n",
    "                t = np.squeeze(out[j])\n",
    "                result[temp] = t\n",
    "                temp+=1\n",
    "        remain = int(np.shape(test_data)[0]-np.floor(np.shape(test_data)[0]/batch_size)*batch_size)\n",
    "        if remain > 0:\n",
    "            x = test_data[-batch_size-1:-1].reshape([batch_size, 1, input_size, 1])\n",
    "            out = sess.run(h_c, feed_dict={p_x:x, keep_prob:1})\n",
    "            for j in range(0,int(remain)):\n",
    "                t = np.squeeze(out[j+(batch_size-remain)])\n",
    "                result[temp] = t\n",
    "                temp+=1\n",
    "        for i in range(0,np.shape(test_data)[0]):\n",
    "            ind = np.argmax(np.squeeze(result[i]))\n",
    "            if ind == test_label[i]:\n",
    "                accuracy += 1\n",
    "        accuracy /= np.shape(test_data)[0]*0.01\n",
    "        sess.close()\n",
    "    return accuracy, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataID = hdf5storage.loadmat('data.mat')\n",
    "data = np.array(dataID['data'], dtype=np.float32)\n",
    "gt1 = scipy.io.loadmat('label.mat')\n",
    "label = np.array(gt1['label'], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Outer_loop = 2\n",
    "Inner_loop = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DNN RandonForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch Loss: 3.372628\n",
      "1 epoch Loss: 3.203314\n",
      "2 epoch Loss: 3.062867\n",
      "3 epoch Loss: 2.923363\n",
      "4 epoch Loss: 2.826230\n",
      "5 epoch Loss: 2.701366\n",
      "6 epoch Loss: 2.626163\n",
      "7 epoch Loss: 2.558419\n",
      "8 epoch Loss: 2.450387\n",
      "9 epoch Loss: 2.407938\n",
      "10 epoch Loss: 2.347855\n",
      "11 epoch Loss: 2.318777\n",
      "12 epoch Loss: 2.237248\n",
      "13 epoch Loss: 2.192678\n",
      "14 epoch Loss: 2.132828\n",
      "15 epoch Loss: 2.142756\n",
      "16 epoch Loss: 2.048900\n",
      "17 epoch Loss: 1.992677\n",
      "18 epoch Loss: 2.026711\n",
      "19 epoch Loss: 1.947907\n",
      "20 epoch Loss: 1.937680\n",
      "21 epoch Loss: 1.883471\n",
      "22 epoch Loss: 1.886932\n",
      "23 epoch Loss: 1.818919\n",
      "24 epoch Loss: 1.834480\n",
      "25 epoch Loss: 1.761302\n",
      "26 epoch Loss: 1.749528\n",
      "27 epoch Loss: 1.706164\n",
      "28 epoch Loss: 1.681559\n",
      "29 epoch Loss: 1.677451\n",
      "30 epoch Loss: 1.660680\n",
      "31 epoch Loss: 1.592473\n",
      "32 epoch Loss: 1.580547\n",
      "33 epoch Loss: 1.634768\n",
      "34 epoch Loss: 1.558004\n",
      "35 epoch Loss: 1.532536\n",
      "36 epoch Loss: 1.497547\n",
      "37 epoch Loss: 1.485069\n",
      "38 epoch Loss: 1.447327\n",
      "39 epoch Loss: 1.478999\n",
      "40 epoch Loss: 1.452560\n",
      "41 epoch Loss: 1.486562\n",
      "42 epoch Loss: 1.429229\n",
      "43 epoch Loss: 1.401065\n",
      "44 epoch Loss: 1.367049\n",
      "45 epoch Loss: 1.378702\n",
      "46 epoch Loss: 1.400092\n",
      "47 epoch Loss: 1.343965\n",
      "48 epoch Loss: 1.321533\n",
      "49 epoch Loss: 1.360315\n",
      "50 epoch Loss: 1.307693\n",
      "51 epoch Loss: 1.326688\n",
      "52 epoch Loss: 1.265985\n",
      "53 epoch Loss: 1.292968\n",
      "54 epoch Loss: 1.276688\n",
      "55 epoch Loss: 1.259048\n",
      "56 epoch Loss: 1.235906\n",
      "57 epoch Loss: 1.250728\n",
      "58 epoch Loss: 1.213830\n",
      "59 epoch Loss: 1.202470\n",
      "60 epoch Loss: 1.207351\n",
      "61 epoch Loss: 1.230197\n",
      "62 epoch Loss: 1.214906\n",
      "63 epoch Loss: 1.153554\n",
      "64 epoch Loss: 1.214143\n",
      "65 epoch Loss: 1.189727\n",
      "66 epoch Loss: 1.158331\n",
      "67 epoch Loss: 1.174143\n",
      "68 epoch Loss: 1.194217\n",
      "69 epoch Loss: 1.157471\n",
      "70 epoch Loss: 1.170709\n",
      "71 epoch Loss: 1.158993\n",
      "72 epoch Loss: 1.128436\n",
      "73 epoch Loss: 1.129102\n",
      "74 epoch Loss: 1.153459\n",
      "75 epoch Loss: 1.099078\n",
      "76 epoch Loss: 1.074131\n",
      "77 epoch Loss: 1.119151\n",
      "78 epoch Loss: 1.146564\n",
      "79 epoch Loss: 1.064984\n",
      "80 epoch Loss: 1.076445\n",
      "81 epoch Loss: 1.089690\n",
      "82 epoch Loss: 1.081446\n",
      "83 epoch Loss: 1.082016\n",
      "84 epoch Loss: 1.053596\n",
      "85 epoch Loss: 1.137932\n",
      "86 epoch Loss: 1.092183\n",
      "87 epoch Loss: 1.032151\n",
      "88 epoch Loss: 1.090835\n",
      "89 epoch Loss: 1.079589\n",
      "90 epoch Loss: 1.073724\n",
      "91 epoch Loss: 1.047926\n",
      "92 epoch Loss: 1.085344\n",
      "93 epoch Loss: 1.103393\n",
      "94 epoch Loss: 1.074835\n",
      "95 epoch Loss: 1.032061\n",
      "96 epoch Loss: 1.115503\n",
      "97 epoch Loss: 1.083230\n",
      "98 epoch Loss: 1.078112\n",
      "99 epoch Loss: 1.061349\n",
      "100 epoch Loss: 1.065992\n",
      "101 epoch Loss: 1.040492\n",
      "102 epoch Loss: 1.032714\n",
      "103 epoch Loss: 1.046676\n",
      "104 epoch Loss: 1.042793\n",
      "105 epoch Loss: 1.065827\n",
      "106 epoch Loss: 1.032602\n",
      "107 epoch Loss: 1.032245\n",
      "108 epoch Loss: 1.060283\n",
      "109 epoch Loss: 1.033239\n",
      "110 epoch Loss: 0.993605\n",
      "111 epoch Loss: 1.023377\n",
      "112 epoch Loss: 1.029505\n",
      "113 epoch Loss: 1.034568\n",
      "114 epoch Loss: 1.066815\n",
      "115 epoch Loss: 1.029897\n",
      "116 epoch Loss: 1.000630\n",
      "117 epoch Loss: 1.034355\n",
      "118 epoch Loss: 1.024572\n",
      "119 epoch Loss: 1.030004\n",
      "Outer_fold # of features:  4000, Neural network accuracy: 80.576978, Random forests accuracy: 70.951157, Ensemble accuracy: 82.405027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#Load data\n",
    "\n",
    "    \n",
    "    #Initialize\n",
    "    label -= 1\n",
    "    np.random.seed(2018)\n",
    "\n",
    "\n",
    "    \n",
    "    t_index = np.random.permutation(int(np.shape(data)[0]/Outer_loop)*Outer_loop)\n",
    "    t_index = np.reshape(t_index, [Outer_loop, -1])\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    \n",
    "    box = np.array([4000], dtype=np.int32)\n",
    "    flag = 0\n",
    "    for test_index in t_index:\n",
    "        if flag == Outer_loop-1:\n",
    "            test_index = np.array(np.concatenate((test_index, np.array(range(int(np.shape(data)[0]/Outer_loop)*Outer_loop,np.shape(data)[0]))), axis=0), dtype=np.int32)\n",
    "        train_index = np.setdiff1d(np.array(range(0,np.shape(data)[0])), test_index)\n",
    "        train_data = data[train_index]\n",
    "        train_label = label[train_index]\n",
    "        test_data = data[test_index]\n",
    "        test_label = label[test_index]\n",
    "        \n",
    "        kf = np.random.permutation(int(np.shape(train_data)[0]/Inner_loop)*Inner_loop)\n",
    "        kf = kf.reshape([Inner_loop]+[-1])\n",
    "        val_result = np.zeros([np.shape(train_data)[0],48], dtype=np.float32)\n",
    "        \n",
    "        tot_acc = np.zeros([Inner_loop,5], dtype=np.float32)\n",
    "        lsvc = LinearSVC(C=1, penalty=\"l1\", dual=False).fit(data, label)\n",
    "        coef = np.squeeze(np.sum(np.square(np.array(lsvc.coef_)), axis=0))\n",
    "        coefidx = np.argsort(coef)\n",
    "\n",
    "        \n",
    "        u = np.sum(tot_acc,0)\n",
    "       \n",
    "        best_n = box[np.argmax(u)]\n",
    "        idx = coefidx[-best_n:]\n",
    "        \n",
    "        tr_data = train_data[:,idx]\n",
    "        te_data = test_data[:,idx]\n",
    "        nn_acc, result_nn = dnn(tr_data, train_label, te_data, test_label)\n",
    "        rf_acc, result_rf = rfc(tr_data, train_label, te_data, test_label)\n",
    "        en_acc = 0.0\n",
    "        for i in range(0,np.shape(te_data)[0]):\n",
    "            r = np.argmax(result_nn[i]+result_rf[i])\n",
    "            if r == test_label[i]:\n",
    "                en_acc += 1\n",
    "        en_acc /= np.shape(te_data)[0]*0.01\n",
    "        print(\"Outer_fold # of features:  %d, Neural network accuracy: %f, Random forests accuracy: %f, Ensemble accuracy: %f\" % (best_n, nn_acc, rf_acc, en_acc))\n",
    "        flag += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network accuracy: 80.576978, Random forests accuracy: 70.951157, Ensemble accuracy: 82.405027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DNN OvrSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch Loss: 3.378391\n",
      "1 epoch Loss: 3.207388\n",
      "2 epoch Loss: 3.077537\n",
      "3 epoch Loss: 2.933593\n",
      "4 epoch Loss: 2.847540\n",
      "5 epoch Loss: 2.722637\n",
      "6 epoch Loss: 2.605994\n",
      "7 epoch Loss: 2.529216\n",
      "8 epoch Loss: 2.471806\n",
      "9 epoch Loss: 2.412961\n",
      "10 epoch Loss: 2.357366\n",
      "11 epoch Loss: 2.273908\n",
      "12 epoch Loss: 2.188370\n",
      "13 epoch Loss: 2.219376\n",
      "14 epoch Loss: 2.153436\n",
      "15 epoch Loss: 2.127754\n",
      "16 epoch Loss: 2.099359\n",
      "17 epoch Loss: 1.978238\n",
      "18 epoch Loss: 1.973884\n",
      "19 epoch Loss: 1.957685\n",
      "20 epoch Loss: 1.926740\n",
      "21 epoch Loss: 1.887076\n",
      "22 epoch Loss: 1.833307\n",
      "23 epoch Loss: 1.821437\n",
      "24 epoch Loss: 1.799424\n",
      "25 epoch Loss: 1.779022\n",
      "26 epoch Loss: 1.719849\n",
      "27 epoch Loss: 1.696606\n",
      "28 epoch Loss: 1.645789\n",
      "29 epoch Loss: 1.702948\n",
      "30 epoch Loss: 1.662552\n",
      "31 epoch Loss: 1.600308\n",
      "32 epoch Loss: 1.613919\n",
      "33 epoch Loss: 1.565426\n",
      "34 epoch Loss: 1.552764\n",
      "35 epoch Loss: 1.499697\n",
      "36 epoch Loss: 1.478473\n",
      "37 epoch Loss: 1.506360\n",
      "38 epoch Loss: 1.451754\n",
      "39 epoch Loss: 1.461858\n",
      "40 epoch Loss: 1.432213\n",
      "41 epoch Loss: 1.404731\n",
      "42 epoch Loss: 1.442696\n",
      "43 epoch Loss: 1.415417\n",
      "44 epoch Loss: 1.364975\n",
      "45 epoch Loss: 1.365248\n",
      "46 epoch Loss: 1.352309\n",
      "47 epoch Loss: 1.337185\n",
      "48 epoch Loss: 1.341557\n",
      "49 epoch Loss: 1.320363\n",
      "50 epoch Loss: 1.325338\n",
      "51 epoch Loss: 1.286656\n",
      "52 epoch Loss: 1.259795\n",
      "53 epoch Loss: 1.289984\n",
      "54 epoch Loss: 1.273302\n",
      "55 epoch Loss: 1.265982\n",
      "56 epoch Loss: 1.261326\n",
      "57 epoch Loss: 1.209662\n",
      "58 epoch Loss: 1.240775\n",
      "59 epoch Loss: 1.265586\n",
      "60 epoch Loss: 1.218200\n",
      "61 epoch Loss: 1.194010\n",
      "62 epoch Loss: 1.185164\n",
      "63 epoch Loss: 1.202467\n",
      "64 epoch Loss: 1.157138\n",
      "65 epoch Loss: 1.159732\n",
      "66 epoch Loss: 1.168644\n",
      "67 epoch Loss: 1.193104\n",
      "68 epoch Loss: 1.167752\n",
      "69 epoch Loss: 1.139429\n",
      "70 epoch Loss: 1.189166\n",
      "71 epoch Loss: 1.140603\n",
      "72 epoch Loss: 1.114033\n",
      "73 epoch Loss: 1.160349\n",
      "74 epoch Loss: 1.153452\n",
      "75 epoch Loss: 1.152992\n",
      "76 epoch Loss: 1.095617\n",
      "77 epoch Loss: 1.135285\n",
      "78 epoch Loss: 1.128526\n",
      "79 epoch Loss: 1.103893\n",
      "80 epoch Loss: 1.097161\n",
      "81 epoch Loss: 1.095673\n",
      "82 epoch Loss: 1.083619\n",
      "83 epoch Loss: 1.096798\n",
      "84 epoch Loss: 1.098144\n",
      "85 epoch Loss: 1.074944\n",
      "86 epoch Loss: 1.087682\n",
      "87 epoch Loss: 1.078210\n",
      "88 epoch Loss: 1.065738\n",
      "89 epoch Loss: 1.112628\n",
      "90 epoch Loss: 1.088245\n",
      "91 epoch Loss: 1.073538\n",
      "92 epoch Loss: 1.077294\n",
      "93 epoch Loss: 1.056960\n",
      "94 epoch Loss: 1.038499\n",
      "95 epoch Loss: 1.068111\n",
      "96 epoch Loss: 1.044403\n",
      "97 epoch Loss: 1.088049\n",
      "98 epoch Loss: 1.064530\n",
      "99 epoch Loss: 1.064694\n",
      "100 epoch Loss: 1.085765\n",
      "101 epoch Loss: 1.040823\n",
      "102 epoch Loss: 1.090415\n",
      "103 epoch Loss: 1.031381\n",
      "104 epoch Loss: 1.028617\n",
      "105 epoch Loss: 1.080657\n",
      "106 epoch Loss: 1.021418\n",
      "107 epoch Loss: 1.030869\n",
      "108 epoch Loss: 1.056866\n",
      "109 epoch Loss: 1.044797\n",
      "110 epoch Loss: 1.038650\n",
      "111 epoch Loss: 1.041819\n",
      "112 epoch Loss: 1.042967\n",
      "113 epoch Loss: 1.043850\n",
      "114 epoch Loss: 1.028794\n",
      "115 epoch Loss: 1.066661\n",
      "116 epoch Loss: 1.029349\n",
      "117 epoch Loss: 1.059442\n",
      "118 epoch Loss: 1.070063\n",
      "119 epoch Loss: 1.042065\n",
      "Outer_fold # of features:  4000, Neural network accuracy: 80.205656, Random forests accuracy: 76.806627, Ensemble accuracy: 81.205370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-af668824d55c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtot_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInner_loop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#lasso = Lasso()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mlsvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"l1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mcoef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#coef = np.squeeze(np.sum(np.square(np.array(lasso.coef_)), axis=0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             self.loss, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"crammer_singer\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    970\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#Load data\n",
    "\n",
    "    \n",
    "    #Initialize\n",
    "    label -= 1\n",
    "    np.random.seed(2018)\n",
    "\n",
    "\n",
    "    \n",
    "    t_index = np.random.permutation(int(np.shape(data)[0]/Outer_loop)*Outer_loop)\n",
    "    t_index = np.reshape(t_index, [Outer_loop, -1])\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    \n",
    "    box = np.array([4000], dtype=np.int32)\n",
    "    flag = 0\n",
    "    for test_index in t_index:\n",
    "        if flag == Outer_loop-1:\n",
    "            test_index = np.array(np.concatenate((test_index, np.array(range(int(np.shape(data)[0]/Outer_loop)*Outer_loop,np.shape(data)[0]))), axis=0), dtype=np.int32)\n",
    "        train_index = np.setdiff1d(np.array(range(0,np.shape(data)[0])), test_index)\n",
    "        train_data = data[train_index]\n",
    "        train_label = label[train_index]\n",
    "        test_data = data[test_index]\n",
    "        test_label = label[test_index]\n",
    "        \n",
    "        kf = np.random.permutation(int(np.shape(train_data)[0]/Inner_loop)*Inner_loop)\n",
    "        kf = kf.reshape([Inner_loop]+[-1])\n",
    "        val_result = np.zeros([np.shape(train_data)[0],48], dtype=np.float32)\n",
    "        \n",
    "        tot_acc = np.zeros([Inner_loop,5], dtype=np.float32)\n",
    "        lsvc = LinearSVC(C=1, penalty=\"l1\", dual=False).fit(data, label)\n",
    "        coef = np.squeeze(np.sum(np.square(np.array(lsvc.coef_)), axis=0))\n",
    "        coefidx = np.argsort(coef)\n",
    "\n",
    "        \n",
    "        u = np.sum(tot_acc,0)\n",
    "       \n",
    "        best_n = box[np.argmax(u)]\n",
    "        idx = coefidx[-best_n:]\n",
    "        \n",
    "        tr_data = train_data[:,idx]\n",
    "        te_data = test_data[:,idx]\n",
    "        nn_acc, result_nn = dnn(tr_data, train_label, te_data, test_label)\n",
    "        rf_acc, result_rf = ovr(tr_data, train_label, te_data, test_label)\n",
    "        en_acc = 0.0\n",
    "        for i in range(0,np.shape(te_data)[0]):\n",
    "            r = np.argmax(result_nn[i]+result_rf[i])\n",
    "            if r == test_label[i]:\n",
    "                en_acc += 1\n",
    "        en_acc /= np.shape(te_data)[0]*0.01\n",
    "        print(\"Outer_fold # of features:  %d, Neural network accuracy: %f, Random forests accuracy: %f, Ensemble accuracy: %f\" % (best_n, nn_acc, rf_acc, en_acc))\n",
    "        flag += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network accuracy: 80.205656, Ovrsvm accuracy: 76.806627, Ensemble accuracy: 81.205370"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DNN KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From <ipython-input-2-6d0cdc7b68c3>:5: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-6-5c2fee5bad1b>:19: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "0 epoch Loss: 3.379283\n",
      "1 epoch Loss: 3.198632\n",
      "2 epoch Loss: 3.062926\n",
      "3 epoch Loss: 2.935328\n",
      "4 epoch Loss: 2.849031\n",
      "5 epoch Loss: 2.742313\n",
      "6 epoch Loss: 2.626125\n",
      "7 epoch Loss: 2.562875\n",
      "8 epoch Loss: 2.484674\n",
      "9 epoch Loss: 2.441144\n",
      "10 epoch Loss: 2.366846\n",
      "11 epoch Loss: 2.308050\n",
      "12 epoch Loss: 2.226232\n",
      "13 epoch Loss: 2.238018\n",
      "14 epoch Loss: 2.149177\n",
      "15 epoch Loss: 2.161984\n",
      "16 epoch Loss: 2.095538\n",
      "17 epoch Loss: 2.037252\n",
      "18 epoch Loss: 2.017752\n",
      "19 epoch Loss: 1.999666\n",
      "20 epoch Loss: 1.918216\n",
      "21 epoch Loss: 1.883197\n",
      "22 epoch Loss: 1.872578\n",
      "23 epoch Loss: 1.836485\n",
      "24 epoch Loss: 1.764731\n",
      "25 epoch Loss: 1.785466\n",
      "26 epoch Loss: 1.730105\n",
      "27 epoch Loss: 1.713619\n",
      "28 epoch Loss: 1.663018\n",
      "29 epoch Loss: 1.721583\n",
      "30 epoch Loss: 1.650979\n",
      "31 epoch Loss: 1.632493\n",
      "32 epoch Loss: 1.607379\n",
      "33 epoch Loss: 1.558820\n",
      "34 epoch Loss: 1.564792\n",
      "35 epoch Loss: 1.525772\n",
      "36 epoch Loss: 1.499343\n",
      "37 epoch Loss: 1.501072\n",
      "38 epoch Loss: 1.536705\n",
      "39 epoch Loss: 1.431440\n",
      "40 epoch Loss: 1.431203\n",
      "41 epoch Loss: 1.419398\n",
      "42 epoch Loss: 1.427308\n",
      "43 epoch Loss: 1.357968\n",
      "44 epoch Loss: 1.362649\n",
      "45 epoch Loss: 1.365147\n",
      "46 epoch Loss: 1.373719\n",
      "47 epoch Loss: 1.352964\n",
      "48 epoch Loss: 1.310113\n",
      "49 epoch Loss: 1.335056\n",
      "50 epoch Loss: 1.335254\n",
      "51 epoch Loss: 1.311009\n",
      "52 epoch Loss: 1.284883\n",
      "53 epoch Loss: 1.294799\n",
      "54 epoch Loss: 1.259287\n",
      "55 epoch Loss: 1.252116\n",
      "56 epoch Loss: 1.283981\n",
      "57 epoch Loss: 1.251077\n",
      "58 epoch Loss: 1.211596\n",
      "59 epoch Loss: 1.219645\n",
      "60 epoch Loss: 1.219807\n",
      "61 epoch Loss: 1.222011\n",
      "62 epoch Loss: 1.182726\n",
      "63 epoch Loss: 1.222125\n",
      "64 epoch Loss: 1.194161\n",
      "65 epoch Loss: 1.195678\n",
      "66 epoch Loss: 1.163339\n",
      "67 epoch Loss: 1.141667\n",
      "68 epoch Loss: 1.134269\n",
      "69 epoch Loss: 1.134819\n",
      "70 epoch Loss: 1.168377\n",
      "71 epoch Loss: 1.124221\n",
      "72 epoch Loss: 1.106211\n",
      "73 epoch Loss: 1.127553\n",
      "74 epoch Loss: 1.149355\n",
      "75 epoch Loss: 1.136843\n",
      "76 epoch Loss: 1.129646\n",
      "77 epoch Loss: 1.154953\n",
      "78 epoch Loss: 1.103822\n",
      "79 epoch Loss: 1.117952\n",
      "80 epoch Loss: 1.110322\n",
      "81 epoch Loss: 1.104665\n",
      "82 epoch Loss: 1.126239\n",
      "83 epoch Loss: 1.080576\n",
      "84 epoch Loss: 1.094177\n",
      "85 epoch Loss: 1.056948\n",
      "86 epoch Loss: 1.095777\n",
      "87 epoch Loss: 1.110804\n",
      "88 epoch Loss: 1.057539\n",
      "89 epoch Loss: 1.115750\n",
      "90 epoch Loss: 1.072511\n",
      "91 epoch Loss: 1.089326\n",
      "92 epoch Loss: 1.112218\n",
      "93 epoch Loss: 1.033201\n",
      "94 epoch Loss: 1.064782\n",
      "95 epoch Loss: 1.078880\n",
      "96 epoch Loss: 1.069244\n",
      "97 epoch Loss: 1.064008\n",
      "98 epoch Loss: 1.022065\n",
      "99 epoch Loss: 1.034564\n",
      "100 epoch Loss: 1.072427\n",
      "101 epoch Loss: 1.027548\n",
      "102 epoch Loss: 1.027345\n",
      "103 epoch Loss: 1.033187\n",
      "104 epoch Loss: 1.031820\n",
      "105 epoch Loss: 1.070568\n",
      "106 epoch Loss: 1.057678\n",
      "107 epoch Loss: 1.074875\n",
      "108 epoch Loss: 1.068625\n",
      "109 epoch Loss: 1.058995\n",
      "110 epoch Loss: 1.028588\n",
      "111 epoch Loss: 1.073003\n",
      "112 epoch Loss: 1.030748\n",
      "113 epoch Loss: 1.007538\n",
      "114 epoch Loss: 1.010307\n",
      "115 epoch Loss: 1.025368\n",
      "116 epoch Loss: 1.025977\n",
      "117 epoch Loss: 1.031926\n",
      "118 epoch Loss: 1.016027\n",
      "119 epoch Loss: 1.066501\n",
      "Outer_fold # of features:  4000, Neural network accuracy: 79.748643, KNN accuracy: 41.902314, Ensemble accuracy: 71.293916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-860065110e7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtot_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInner_loop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#lasso = Lasso()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mlsvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"l1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mcoef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#coef = np.squeeze(np.sum(np.square(np.array(lasso.coef_)), axis=0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             self.loss, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"crammer_singer\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    970\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#Load data\n",
    "\n",
    "    \n",
    "    #Initialize\n",
    "    label -= 1\n",
    "    np.random.seed(2018)\n",
    "\n",
    "\n",
    "    \n",
    "    t_index = np.random.permutation(int(np.shape(data)[0]/Outer_loop)*Outer_loop)\n",
    "    t_index = np.reshape(t_index, [Outer_loop, -1])\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    \n",
    "    box = np.array([4000], dtype=np.int32)\n",
    "    flag = 0\n",
    "    for test_index in t_index:\n",
    "        if flag == Outer_loop-1:\n",
    "            test_index = np.array(np.concatenate((test_index, np.array(range(int(np.shape(data)[0]/Outer_loop)*Outer_loop,np.shape(data)[0]))), axis=0), dtype=np.int32)\n",
    "        train_index = np.setdiff1d(np.array(range(0,np.shape(data)[0])), test_index)\n",
    "        train_data = data[train_index]\n",
    "        train_label = label[train_index]\n",
    "        test_data = data[test_index]\n",
    "        test_label = label[test_index]\n",
    "        \n",
    "        kf = np.random.permutation(int(np.shape(train_data)[0]/Inner_loop)*Inner_loop)\n",
    "        kf = kf.reshape([Inner_loop]+[-1])\n",
    "        val_result = np.zeros([np.shape(train_data)[0],48], dtype=np.float32)\n",
    "        \n",
    "        tot_acc = np.zeros([Inner_loop,5], dtype=np.float32)\n",
    "        lsvc = LinearSVC(C=1, penalty=\"l1\", dual=False).fit(data, label)\n",
    "        coef = np.squeeze(np.sum(np.square(np.array(lsvc.coef_)), axis=0))\n",
    "        coefidx = np.argsort(coef)\n",
    "        \n",
    "        u = np.sum(tot_acc,0)\n",
    "        \n",
    "       \n",
    "        best_n = box[np.argmax(u)]\n",
    "        idx = coefidx[-best_n:]\n",
    "        \n",
    "        tr_data = train_data[:,idx]\n",
    "        te_data = test_data[:,idx]\n",
    "        nn_acc, result_nn = dnn(tr_data, train_label, te_data, test_label)\n",
    "        rf_acc, result_rf = KNN(tr_data, train_label, te_data, test_label)\n",
    "        en_acc = 0.0\n",
    "        for i in range(0,np.shape(te_data)[0]):\n",
    "            r = np.argmax(result_nn[i]+result_rf[i])\n",
    "            if r == test_label[i]:\n",
    "                en_acc += 1\n",
    "        en_acc /= np.shape(te_data)[0]*0.01\n",
    "        print(\"Outer_fold # of features:  %d, Neural network accuracy: %f, KNN accuracy: %f, Ensemble accuracy: %f\" % (best_n, nn_acc, rf_acc, en_acc))\n",
    "        flag += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network accuracy: 79.748643, KNN accuracy: 41.902314, Ensemble accuracy: 71.293916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandonForest OvrSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer_fold # of features:  4000, Ovrsvm accuracy: 76.949443, KNN accuracy: 70.951157, Ensemble accuracy: 80.177092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer_fold # of features:  4000, Ovrsvm accuracy: 75.921165, KNN accuracy: 71.093973, Ensemble accuracy: 78.834619\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#Load data\n",
    "\n",
    "    \n",
    "    #Initialize\n",
    "    label -= 1\n",
    "    np.random.seed(2018)\n",
    "\n",
    "\n",
    "    \n",
    "    t_index = np.random.permutation(int(np.shape(data)[0]/Outer_loop)*Outer_loop)\n",
    "    t_index = np.reshape(t_index, [Outer_loop, -1])\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    \n",
    "    box = np.array([4000], dtype=np.int32)\n",
    "    flag = 0\n",
    "    for test_index in t_index:\n",
    "        if flag == Outer_loop-1:\n",
    "            test_index = np.array(np.concatenate((test_index, np.array(range(int(np.shape(data)[0]/Outer_loop)*Outer_loop,np.shape(data)[0]))), axis=0), dtype=np.int32)\n",
    "        train_index = np.setdiff1d(np.array(range(0,np.shape(data)[0])), test_index)\n",
    "        train_data = data[train_index]\n",
    "        train_label = label[train_index]\n",
    "        test_data = data[test_index]\n",
    "        test_label = label[test_index]\n",
    "        \n",
    "        kf = np.random.permutation(int(np.shape(train_data)[0]/Inner_loop)*Inner_loop)\n",
    "        kf = kf.reshape([Inner_loop]+[-1])\n",
    "        val_result = np.zeros([np.shape(train_data)[0],48], dtype=np.float32)\n",
    "        \n",
    "        tot_acc = np.zeros([Inner_loop,5], dtype=np.float32)\n",
    "        lsvc = LinearSVC(C=1, penalty=\"l1\", dual=False).fit(data, label)\n",
    "        coef = np.squeeze(np.sum(np.square(np.array(lsvc.coef_)), axis=0))\n",
    "        coefidx = np.argsort(coef)\n",
    "\n",
    "        \n",
    "        u = np.sum(tot_acc,0)\n",
    "        \n",
    "       \n",
    "        best_n = box[np.argmax(u)]\n",
    "        idx = coefidx[-best_n:]\n",
    "        \n",
    "        tr_data = train_data[:,idx]\n",
    "        te_data = test_data[:,idx]\n",
    "        nn_acc, result_nn = ovr(tr_data, train_label, te_data, test_label)\n",
    "        rf_acc, result_rf = rfc(tr_data, train_label, te_data, test_label)\n",
    "        en_acc = 0.0\n",
    "        for i in range(0,np.shape(te_data)[0]):\n",
    "            r = np.argmax(result_nn[i]+result_rf[i])\n",
    "            if r == test_label[i]:\n",
    "                en_acc += 1\n",
    "        en_acc /= np.shape(te_data)[0]*0.01\n",
    "        print(\"Outer_fold # of features:  %d, Ovrsvm accuracy: %f, KNN accuracy: %f, Ensemble accuracy: %f\" % (best_n, nn_acc, rf_acc, en_acc))\n",
    "        flag += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandonForest KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer_fold # of features:  4000, KNN accuracy: 41.902314, Random Forest accuracy: 70.951157, Ensemble accuracy: 58.954584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c83f50b99893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtot_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInner_loop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#lasso = Lasso()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mlsvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"l1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mcoef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#coef = np.squeeze(np.sum(np.square(np.array(lasso.coef_)), axis=0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             self.loss, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"crammer_singer\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    970\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#Load data\n",
    "\n",
    "    \n",
    "    #Initialize\n",
    "    label -= 1\n",
    "    np.random.seed(2018)\n",
    "\n",
    "\n",
    "    \n",
    "    t_index = np.random.permutation(int(np.shape(data)[0]/Outer_loop)*Outer_loop)\n",
    "    t_index = np.reshape(t_index, [Outer_loop, -1])\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    \n",
    "    box = np.array([4000], dtype=np.int32)\n",
    "    flag = 0\n",
    "    for test_index in t_index:\n",
    "        if flag == Outer_loop-1:\n",
    "            test_index = np.array(np.concatenate((test_index, np.array(range(int(np.shape(data)[0]/Outer_loop)*Outer_loop,np.shape(data)[0]))), axis=0), dtype=np.int32)\n",
    "        train_index = np.setdiff1d(np.array(range(0,np.shape(data)[0])), test_index)\n",
    "        train_data = data[train_index]\n",
    "        train_label = label[train_index]\n",
    "        test_data = data[test_index]\n",
    "        test_label = label[test_index]\n",
    "        \n",
    "        kf = np.random.permutation(int(np.shape(train_data)[0]/Inner_loop)*Inner_loop)\n",
    "        kf = kf.reshape([Inner_loop]+[-1])\n",
    "        val_result = np.zeros([np.shape(train_data)[0],48], dtype=np.float32)\n",
    "        \n",
    "        tot_acc = np.zeros([Inner_loop,5], dtype=np.float32)\n",
    "        lsvc = LinearSVC(C=1, penalty=\"l1\", dual=False).fit(data, label)\n",
    "        coef = np.squeeze(np.sum(np.square(np.array(lsvc.coef_)), axis=0))\n",
    "        coefidx = np.argsort(coef)\n",
    "\n",
    "        u = np.sum(tot_acc,0)\n",
    "        \n",
    "       \n",
    "        best_n = box[np.argmax(u)]\n",
    "        idx = coefidx[-best_n:]\n",
    "        \n",
    "        tr_data = train_data[:,idx]\n",
    "        te_data = test_data[:,idx]\n",
    "        nn_acc, result_nn = KNN(tr_data, train_label, te_data, test_label)\n",
    "        rf_acc, result_rf = rfc(tr_data, train_label, te_data, test_label)\n",
    "        en_acc = 0.0\n",
    "        for i in range(0,np.shape(te_data)[0]):\n",
    "            r = np.argmax(result_nn[i]+result_rf[i])\n",
    "            if r == test_label[i]:\n",
    "                en_acc += 1\n",
    "        en_acc /= np.shape(te_data)[0]*0.01\n",
    "        print(\"Outer_fold # of features:  %d, KNN accuracy: %f, Random Forest accuracy: %f, Ensemble accuracy: %f\" % (best_n, nn_acc, rf_acc, en_acc))\n",
    "        flag += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN accuracy: 41.902314, Random Forest accuracy: 70.951157, Ensemble accuracy: 58.954584"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OvrSVM KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer_fold # of features:  4000, OvrSVM accuracy: 76.949443, KNN accuracy: 41.902314, Ensemble accuracy: 64.952871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/sophie52052/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer_fold # of features:  4000, OvrSVM accuracy: 75.921165, KNN accuracy: 42.330763, Ensemble accuracy: 63.267638\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#Load data\n",
    "\n",
    "    \n",
    "    #Initialize\n",
    "    label -= 1\n",
    "    np.random.seed(2018)\n",
    "\n",
    "\n",
    "    \n",
    "    t_index = np.random.permutation(int(np.shape(data)[0]/Outer_loop)*Outer_loop)\n",
    "    t_index = np.reshape(t_index, [Outer_loop, -1])\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    \n",
    "    box = np.array([4000], dtype=np.int32)\n",
    "    flag = 0\n",
    "    for test_index in t_index:\n",
    "        if flag == Outer_loop-1:\n",
    "            test_index = np.array(np.concatenate((test_index, np.array(range(int(np.shape(data)[0]/Outer_loop)*Outer_loop,np.shape(data)[0]))), axis=0), dtype=np.int32)\n",
    "        train_index = np.setdiff1d(np.array(range(0,np.shape(data)[0])), test_index)\n",
    "        train_data = data[train_index]\n",
    "        train_label = label[train_index]\n",
    "        test_data = data[test_index]\n",
    "        test_label = label[test_index]\n",
    "        \n",
    "        kf = np.random.permutation(int(np.shape(train_data)[0]/Inner_loop)*Inner_loop)\n",
    "        kf = kf.reshape([Inner_loop]+[-1])\n",
    "        val_result = np.zeros([np.shape(train_data)[0],48], dtype=np.float32)\n",
    "        \n",
    "        tot_acc = np.zeros([Inner_loop,5], dtype=np.float32)\n",
    "        lsvc = LinearSVC(C=1, penalty=\"l1\", dual=False).fit(data, label)\n",
    "        coef = np.squeeze(np.sum(np.square(np.array(lsvc.coef_)), axis=0))\n",
    "        coefidx = np.argsort(coef)\n",
    "\n",
    "        \n",
    "        u = np.sum(tot_acc,0)\n",
    "        \n",
    "       \n",
    "        best_n = box[np.argmax(u)]\n",
    "        idx = coefidx[-best_n:]\n",
    "        \n",
    "        tr_data = train_data[:,idx]\n",
    "        te_data = test_data[:,idx]\n",
    "        nn_acc, result_nn = ovr(tr_data, train_label, te_data, test_label)\n",
    "        rf_acc, result_rf = KNN(tr_data, train_label, te_data, test_label)\n",
    "        en_acc = 0.0\n",
    "        for i in range(0,np.shape(te_data)[0]):\n",
    "            r = np.argmax(result_nn[i]+result_rf[i])\n",
    "            if r == test_label[i]:\n",
    "                en_acc += 1\n",
    "        en_acc /= np.shape(te_data)[0]*0.01\n",
    "        print(\"Outer_fold # of features:  %d, OvrSVM accuracy: %f, KNN accuracy: %f, Ensemble accuracy: %f\" % (best_n, nn_acc, rf_acc, en_acc))\n",
    "        flag += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MD_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Accuracy':MD_acc,'Feature Select':MD_sel, 'Model':MD_md}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Feature Select</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.571429</td>\n",
       "      <td>no select</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79.571429</td>\n",
       "      <td>no select</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.571429</td>\n",
       "      <td>no select</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.285714</td>\n",
       "      <td>no select</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.571429</td>\n",
       "      <td>no select</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>72.857143</td>\n",
       "      <td>lsvc</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>72.714286</td>\n",
       "      <td>lsvc</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>75.714286</td>\n",
       "      <td>lsvc</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>lsvc</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>72.507123</td>\n",
       "      <td>lsvc</td>\n",
       "      <td>random forest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy Feature Select          Model\n",
       "0    80.571429      no select       ensemble\n",
       "1    79.571429      no select       ensemble\n",
       "2    80.571429      no select       ensemble\n",
       "3    79.285714      no select       ensemble\n",
       "4    79.571429      no select       ensemble\n",
       "..         ...            ...            ...\n",
       "115  72.857143           lsvc  random forest\n",
       "116  72.714286           lsvc  random forest\n",
       "117  75.714286           lsvc  random forest\n",
       "118  74.000000           lsvc  random forest\n",
       "119  72.507123           lsvc  random forest\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
